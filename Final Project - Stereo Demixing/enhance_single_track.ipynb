{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22ananya/MUSI6201/blob/main/Final%20Project%20-%20Stereo%20Demixing/enhance_single_track.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RybrH0gAWbaJ"
      },
      "source": [
        "Import generally required packages - update as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tj5sXc5LWHpQ"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import scipy.signal as sp\n",
        "import scipy.io.wavfile as wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW5-Sa5pYuUN"
      },
      "source": [
        "Import/Install the prerequisite code for implementing the Cadenza challenge - includes baselines, other important files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "rgBYSep2Y6UT",
        "outputId": "4ad3dca3-d270-4dce-9100-9e21d1b4c475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyclarity==0.4.0\n",
            "  Downloading pyclarity-0.4.0-py3-none-any.whl (750 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/750.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/750.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (3.0.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (4.6.6)\n",
            "Collecting hydra-core>=1.1.1 (from pyclarity==0.4.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-submitit-launcher>=1.1.6 (from pyclarity==0.4.0)\n",
            "  Downloading hydra_submitit_launcher-1.2.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (6.8.0)\n",
            "Requirement already satisfied: librosa>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (3.7.1)\n",
            "Requirement already satisfied: numba>=0.57.0rc in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (0.58.1)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (1.23.5)\n",
            "Collecting omegaconf>=2.1.1 (from pyclarity==0.4.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (1.5.3)\n",
            "Collecting pyflac (from pyclarity==0.4.0)\n",
            "  Downloading pyFLAC-2.2.0.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyloudnorm>=0.1.0 (from pyclarity==0.4.0)\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Collecting pystoi (from pyclarity==0.4.0)\n",
            "  Downloading pystoi-0.3.3.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-lightning (from pyclarity==0.4.0)\n",
            "  Downloading pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.9/776.9 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting resampy (from pyclarity==0.4.0)\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (1.11.3)\n",
            "Requirement already satisfied: SoundFile>=0.10.3.post1 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (0.12.1)\n",
            "Requirement already satisfied: soxr in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (0.3.7)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyclarity==0.4.0) (4.5.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1.1->pyclarity==0.4.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.1->pyclarity==0.4.0) (23.2)\n",
            "Collecting submitit>=1.3.3 (from hydra-submitit-launcher>=1.1.6->pyclarity==0.4.0)\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.1->pyclarity==0.4.0) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.1->pyclarity==0.4.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.1->pyclarity==0.4.0) (1.8.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.1->pyclarity==0.4.0) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.8.1->pyclarity==0.4.0) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0rc->pyclarity==0.4.0) (0.41.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.1.1->pyclarity==0.4.0) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pyclarity==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pyclarity==0.4.0) (2023.3.post1)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm>=0.1.0->pyclarity==0.4.0) (0.18.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pyclarity==0.4.0) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.3.post1->pyclarity==0.4.0) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->pyclarity==0.4.0) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->pyclarity==0.4.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->pyclarity==0.4.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->pyclarity==0.4.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->pyclarity==0.4.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->pyclarity==0.4.0) (2.1.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->pyclarity==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown->pyclarity==0.4.0) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->pyclarity==0.4.0) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->pyclarity==0.4.0) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyclarity==0.4.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyclarity==0.4.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyclarity==0.4.0) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyclarity==0.4.0) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyclarity==0.4.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyclarity==0.4.0) (3.1.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning->pyclarity==0.4.0)\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.8.0 (from pytorch-lightning->pyclarity==0.4.0)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.3.post1->pyclarity==0.4.0) (2.21)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch>=2->pyclarity==0.4.0) (3.8.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning->pyclarity==0.4.0) (67.7.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.8.1->pyclarity==0.4.0) (4.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit>=1.3.3->hydra-submitit-launcher>=1.1.6->pyclarity==0.4.0) (2.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->pyclarity==0.4.0) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->pyclarity==0.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->pyclarity==0.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->pyclarity==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->pyclarity==0.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->pyclarity==0.4.0) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->pyclarity==0.4.0) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->pyclarity==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->pyclarity==0.4.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->pyclarity==0.4.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->pyclarity==0.4.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->pyclarity==0.4.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->pyclarity==0.4.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->pyclarity==0.4.0) (1.3.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, pyflac, pystoi\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=c33b987e1b819222add82db75f4555e96404829930ad970e651c139659d5aa74\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for pyflac (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyflac: filename=pyFLAC-2.2.0-cp310-cp310-linux_x86_64.whl size=1682412 sha256=9fd47d413859a375b3b68e2ebec56271640859aa8e0ff4b8e17863dc8701bf99\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/48/5e/2886846557610648e498e722559426a62d24b858db2cc8d248\n",
            "  Building wheel for pystoi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystoi: filename=pystoi-0.3.3-py2.py3-none-any.whl size=7777 sha256=e14cb66809c76c0022f363c96bd59a2e58691690ba2336f9ef19efc7895e8f6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/ca/9e/5b5d6e5e109322303b50d21918ad2bd7d50a2a0775c11e08e8\n",
            "Successfully built antlr4-python3-runtime pyflac pystoi\n",
            "Installing collected packages: antlr4-python3-runtime, submitit, omegaconf, lightning-utilities, resampy, pystoi, pyloudnorm, hydra-core, torchmetrics, pyflac, hydra-submitit-launcher, pytorch-lightning, pyclarity\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 hydra-submitit-launcher-1.2.0 lightning-utilities-0.10.0 omegaconf-2.3.0 pyclarity-0.4.0 pyflac-2.2.0 pyloudnorm-0.1.1 pystoi-0.3.3 pytorch-lightning-2.1.2 resampy-0.4.2 submitit-1.5.1 torchmetrics-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pyclarity==0.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vLsywcTb5FB"
      },
      "source": [
        "Import the dataset for the Cadenza challenge directly through the Google Drive link - Only needs to be done once! So now commented out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtLL_IXb_kz",
        "outputId": "c2f30483-a966-42e7-9b47-ed9dfb7e8a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uOllNXFfDlh"
      },
      "source": [
        "Check current path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmCaU0XNfHu6",
        "outputId": "2268c0db-e6b0-4f40-f427-9fdd6ddcc72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys7wmmN00ZpY"
      },
      "source": [
        "Change current path to Cadenza folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us9_BSIi0gOM",
        "outputId": "4899abc7-195f-4505-8d6f-0bb107f7c1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024')\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIV3qhN6x5si"
      },
      "source": [
        "#Process single audio file through the entire model step by step"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all dependencies - same as enhance.py file"
      ],
      "metadata": {
        "id": "XzG_c2u33Rdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# pylint: disable=import-error\n",
        "import hydra\n",
        "import numpy as np\n",
        "import torch\n",
        "from numpy import ndarray\n",
        "from omegaconf import DictConfig\n",
        "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB\n",
        "\n",
        "from clarity.enhancer.compressor import Compressor\n",
        "from clarity.enhancer.nalr import NALR\n",
        "from clarity.utils.audiogram import Listener\n",
        "from clarity.utils.file_io import read_signal\n",
        "from clarity.utils.flac_encoder import FlacEncoder\n",
        "from clarity.utils.signal_processing import (\n",
        "    clip_signal,\n",
        "    denormalize_signals,\n",
        "    normalize_signal,\n",
        "    resample,\n",
        "    to_16bit,\n",
        ")\n",
        "from clarity.utils.source_separation_support import get_device, separate_sources\n",
        "from recipes.cad_icassp_2024.baseline.evaluate import (\n",
        "    apply_gains,\n",
        "    apply_ha,\n",
        "    make_scene_listener_list,\n",
        "    remix_stems,\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXGfszFA3pOl",
        "outputId": "46d31708-2217-4f92-9dc6-4297b0fa9d56"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recipes/cad_icassp_2024/baseline/evaluate.py:190: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  @hydra.main(config_path=\"\", config_name=\"config\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the required functions defined in Enhance.py that do not need to be changed"
      ],
      "metadata": {
        "id": "9CAxXIQs3yPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from recipes.cad_icassp_2024.baseline.enhance import (\n",
        "    save_flac_signal,\n",
        "    decompose_signal,\n",
        "    process_remix_for_listener\n",
        ")"
      ],
      "metadata": {
        "id": "fO7Ke41s34zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8b46bc-aa9d-489b-bb0e-b47bd6ab7ff7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recipes/cad_icassp_2024/baseline/enhance.py:182: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  @hydra.main(config_path=\"\", config_name=\"config\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the correct config file (hardcoded location)"
      ],
      "metadata": {
        "id": "HInm_0fO6bIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from omegaconf import OmegaConf\n",
        "config = OmegaConf.load('baseline/config.yaml')\n",
        "print(config.separator.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QraRFr8K5VyB",
        "outputId": "c36380b9-c0f1-4140-ee60-e1667f46002d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demucs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set output directory"
      ],
      "metadata": {
        "id": "8YfLt5Py4whx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enhanced_folder = Path(\"enhanced_signals_single\")\n",
        "enhanced_folder.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "ltHsRuxw4zm4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load source sep model  - pretrained"
      ],
      "metadata": {
        "id": "kmTdcmZ55Lfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if config.separator.model == \"demucs\":\n",
        "    separation_model = HDEMUCS_HIGH_MUSDB.get_model()\n",
        "    model_sample_rate = HDEMUCS_HIGH_MUSDB.sample_rate\n",
        "    sources_order = separation_model.sources\n",
        "    normalise = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0rhbrLK5Pcs",
        "outputId": "abd26eaf-d288-41d4-8bf5-2b6aec379b5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 319M/319M [00:06<00:00, 47.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure device"
      ],
      "metadata": {
        "id": "5Na-Sqdg5c-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device, _ = get_device(config.separator.device)\n",
        "separation_model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHtYpYFY5eNH",
        "outputId": "6f8531d6-34b9-4426-fd46-af334893a420"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HDemucs(\n",
              "  (freq_encoder): ModuleList(\n",
              "    (0): _HEncLayer(\n",
              "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): _HEncLayer(\n",
              "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): _HEncLayer(\n",
              "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): _HEncLayer(\n",
              "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): _HEncLayer(\n",
              "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): _HEncLayer(\n",
              "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (freq_decoder): ModuleList(\n",
              "    (0): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
              "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
              "    )\n",
              "    (1): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
              "    )\n",
              "    (2): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (3): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (4): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (5): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "  )\n",
              "  (time_encoder): ModuleList(\n",
              "    (0): _HEncLayer(\n",
              "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): _HEncLayer(\n",
              "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): _HEncLayer(\n",
              "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): _HEncLayer(\n",
              "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): _HEncLayer(\n",
              "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
              "      (rewrite): Identity()\n",
              "      (norm2): Identity()\n",
              "      (dconv): Identity()\n",
              "    )\n",
              "  )\n",
              "  (time_decoder): ModuleList(\n",
              "    (0): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
              "      (rewrite): Identity()\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (1): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (2): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (3): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (4): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "  )\n",
              "  (freq_emb): _ScaledEmbedding(\n",
              "    (embedding): Embedding(512, 48)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load listener data"
      ],
      "metadata": {
        "id": "1byRhXrc5nmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config.path.root = '/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024'\n",
        "print(config.path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE-6z8e6cdL",
        "outputId": "ea833679-1346-4f5f-968e-68e36deb9798"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'root': '/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024', 'metadata_dir': '${path.root}/metadata', 'music_dir': '${path.root}/audio/at_mic_music', 'gains_file': '${path.metadata_dir}/gains.json', 'head_positions_file': '${path.metadata_dir}/head_positions.json', 'listeners_file': '${path.metadata_dir}/listeners.train.json', 'music_file': '${path.metadata_dir}/at_mic_music.train.json', 'scenes_file': '${path.metadata_dir}/scenes.train.json', 'scene_listeners_file': '${path.metadata_dir}/scene_listeners.train.json', 'exp_folder': './exp'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load listener audiograms and songs\n",
        "listener_dict = Listener.load_listener_dict(config.path.listeners_file)\n",
        "\n",
        "with Path(config.path.gains_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    gains = json.load(file)\n",
        "\n",
        "with Path(config.path.scenes_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    scenes = json.load(file)\n",
        "\n",
        "with Path(config.path.scene_listeners_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    scenes_listeners = json.load(file)\n",
        "\n",
        "with Path(config.path.music_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    songs = json.load(file)"
      ],
      "metadata": {
        "id": "W00FlI6A5pnr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the enhancer (NAL-R) and compression setting (OFF)"
      ],
      "metadata": {
        "id": "OHqV6DQt7W2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enhancer = NALR(**config.nalr)\n",
        "compressor = Compressor(**config.compressor)"
      ],
      "metadata": {
        "id": "SvGqWrBN7cXa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list of songs, listeners (audiogram) and head position (hrtf) to generate, or evaluate the mix - based on provided data"
      ],
      "metadata": {
        "id": "UwQqYlq88GQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a batch to process\n",
        "scene_listener_pairs = make_scene_listener_list(\n",
        "    scenes_listeners, config.evaluate.small_test\n",
        ")\n",
        "\n",
        "scene_listener_pairs = scene_listener_pairs[\n",
        "    config.evaluate.batch :: config.evaluate.batch_size\n",
        "]"
      ],
      "metadata": {
        "id": "QSgNSyzC8U5e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scene_listener_pairs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW8ZQ0fE88nr",
        "outputId": "7727a6e9-fa8d-41e9-a312-9e08ecdb6e8f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('scene_10001', 'L0066')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Audio - Currently set to process a fixed number of runs (listener - scene pairings, can be changed to run entire dataset)"
      ],
      "metadata": {
        "id": "GU9VumyD93Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previous_song = \"\"\n",
        "num_scenes = len(scene_listener_pairs)\n",
        "nrun = 1 # change to num_scenes for full dataset\n",
        "\n",
        "for idx in range(nrun):\n",
        "    scene_id, listener_id = scene_listener_pairs[idx]\n",
        "\n",
        "    scene = scenes[scene_id]\n",
        "    song_name = f\"{scene['music']}-{scene['head_loudspeaker_positions']}\"\n",
        "\n",
        "    logger.info(\n",
        "        f\"[{idx:03d}/{num_scenes:03d}] \"\n",
        "        f\"Processing {scene_id}: {song_name} for listener {listener_id}\"\n",
        "    )\n",
        "    # Get the listener's audiogram\n",
        "    listener = listener_dict[listener_id]\n",
        "\n",
        "\n",
        "    # Read the binaural mixture, preprocess and then demix\n",
        "\n",
        "\n",
        "    # Convert to 32-bit floating point and transpose\n",
        "    # from [samples, channels] to [channels, samples]\n",
        "    if song_name != previous_song:\n",
        "        mixture_signal = read_signal(\n",
        "            filename=Path(config.path.music_dir)\n",
        "            / songs[song_name][\"Path\"]\n",
        "            / \"mixture.wav\",\n",
        "            sample_rate=config.sample_rate,\n",
        "            allow_resample=True,\n",
        "        )\n",
        "\n",
        "        # demix\n",
        "        stems: dict[str, ndarray] = decompose_signal(\n",
        "            model=separation_model,\n",
        "            model_sample_rate=model_sample_rate,\n",
        "            signal=mixture_signal,\n",
        "            signal_sample_rate=config.sample_rate,\n",
        "            device=device,\n",
        "            sources_list=sources_order,\n",
        "            listener=listener,\n",
        "            normalise=normalise,\n",
        "        )\n",
        "\n",
        "        # Reweight the stems based on provided gains and downmix to stereo\n",
        "        stems = apply_gains(stems, config.sample_rate, gains[scene[\"gain\"]])\n",
        "        enhanced_signal = remix_stems(stems, mixture_signal, model_sample_rate)\n",
        "\n",
        "    # Enhance the signal: Process through Hearing Aid processing - NAL-R gain application and optional compression\n",
        "    enhanced_signal = process_remix_for_listener(\n",
        "    signal=enhanced_signal,\n",
        "    enhancer=enhancer,\n",
        "    compressor=compressor,\n",
        "    listener=listener,\n",
        "    apply_compressor=config.apply_compressor,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Write to file! - Make sure the enhanced_folder directory is correct\n",
        "    filename = Path(enhanced_folder) / f\"{scene_id}_{listener.id}_remix.flac\"\n",
        "\n",
        "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
        "    save_flac_signal(\n",
        "        signal=enhanced_signal,\n",
        "        filename=filename,\n",
        "        signal_sample_rate=config.sample_rate,\n",
        "        output_sample_rate=config.remix_sample_rate,\n",
        "        do_clip_signal=True,\n",
        "        do_soft_clip=config.soft_clip,\n",
        "        )\n",
        "\n",
        "logger.info(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3e71Ato-IyR",
        "outputId": "bdea3e03-93b7-4cd7-bfd2-d0cfb2063e78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:recipes.cad_icassp_2024.baseline.enhance:Writing enhanced_signals_single/scene_10001_L0066_remix.flac: 4423459 samples clipped\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}