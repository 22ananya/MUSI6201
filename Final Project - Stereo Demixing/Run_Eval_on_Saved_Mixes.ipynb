{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22ananya/MUSI6201/blob/main/Final%20Project%20-%20Stereo%20Demixing/Run_Eval_on_Saved_Mixes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RybrH0gAWbaJ"
      },
      "source": [
        "Import generally required packages - update as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tj5sXc5LWHpQ"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import scipy.signal as sp\n",
        "import scipy.io.wavfile as wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW5-Sa5pYuUN"
      },
      "source": [
        "Import/Install the prerequisite code for implementing the Cadenza challenge - includes baselines, other important files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install pyclarity==0.4.0"
      ],
      "metadata": {
        "id": "rgBYSep2Y6UT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vLsywcTb5FB"
      },
      "source": [
        "Import the dataset for the Cadenza challenge directly through the Google Drive link - Only needs to be done once! So now commented out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtLL_IXb_kz",
        "outputId": "09052c43-0417-4ac7-d805-4218a398ce30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uOllNXFfDlh"
      },
      "source": [
        "Check current path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmCaU0XNfHu6",
        "outputId": "84738aab-139c-44bf-901b-7a4f427345c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys7wmmN00ZpY"
      },
      "source": [
        "Change current path to Cadenza folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us9_BSIi0gOM",
        "outputId": "bdec1acc-4e34-48f4-aae3-b9fffdd36b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024')\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIV3qhN6x5si"
      },
      "source": [
        "#Process single audio file through the entire model step by step"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all dependencies - same as enhance.py file"
      ],
      "metadata": {
        "id": "XzG_c2u33Rdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# pylint: disable=import-error\n",
        "import hydra\n",
        "import numpy as np\n",
        "import torch\n",
        "from numpy import ndarray\n",
        "from omegaconf import DictConfig\n",
        "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB\n",
        "\n",
        "from clarity.enhancer.compressor import Compressor\n",
        "from clarity.enhancer.nalr import NALR\n",
        "from clarity.evaluator.haaqi import compute_haaqi\n",
        "from clarity.utils.audiogram import Audiogram, Listener\n",
        "from clarity.utils.file_io import read_signal\n",
        "from clarity.utils.flac_encoder import FlacEncoder\n",
        "from clarity.utils.results_support import ResultsFile\n",
        "from clarity.utils.signal_processing import (\n",
        "    clip_signal,\n",
        "    denormalize_signals,\n",
        "    normalize_signal,\n",
        "    resample,\n",
        "    to_16bit,\n",
        "    compute_rms,\n",
        "    resample,\n",
        ")\n",
        "from clarity.utils.source_separation_support import get_device, separate_sources\n",
        "from recipes.cad_icassp_2024.baseline.evaluate import (\n",
        "    apply_gains,\n",
        "    apply_ha,\n",
        "    make_scene_listener_list,\n",
        "    remix_stems,\n",
        "    load_reference_stems,\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXGfszFA3pOl",
        "outputId": "6f1afb50-7183-4274-b3c3-016d00161c9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recipes/cad_icassp_2024/baseline/evaluate.py:190: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  @hydra.main(config_path=\"\", config_name=\"config\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the required functions defined in Enhance.py that do not need to be changed"
      ],
      "metadata": {
        "id": "9CAxXIQs3yPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from recipes.cad_icassp_2024.baseline.enhance import (\n",
        "    save_flac_signal,\n",
        "    decompose_signal,\n",
        "    process_remix_for_listener\n",
        ")"
      ],
      "metadata": {
        "id": "fO7Ke41s34zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d955c15-9188-4716-ad7a-fa2d9296ce0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recipes/cad_icassp_2024/baseline/enhance.py:182: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  @hydra.main(config_path=\"\", config_name=\"config\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the correct config file (hardcoded location)"
      ],
      "metadata": {
        "id": "HInm_0fO6bIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from omegaconf import OmegaConf\n",
        "config = OmegaConf.load('baseline/config.yaml')\n",
        "print(config.separator.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QraRFr8K5VyB",
        "outputId": "10975949-011f-495e-b821-7e98a8161932"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demucs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set input directory"
      ],
      "metadata": {
        "id": "8YfLt5Py4whx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_folder = Path(\"ref_signals_100\")\n",
        "enhanced_mix_folder = Path(\"enhanced_signals_100tracks\")"
      ],
      "metadata": {
        "id": "ltHsRuxw4zm4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load the audio files in provided path"
      ],
      "metadata": {
        "id": "DhjLl27kX1sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enhanced_files = [] # initialize list of enhanced audio files\n",
        "reference_files = [] # initialize list of reference files\n",
        "for file in os.listdir(enhanced_mix_folder): # iterate over all files in the directory\n",
        "    if file.endswith('.flac'): # if the file is an audio file\n",
        "        enhanced_files.append(os.path.join(enhanced_mix_folder, file)) # add the file to the list of audio files\n",
        "        reference_files.append(os.path.join(reference_folder, file.replace('.flac','_ref.flac'))) # add the corresponding ref file to the list of ref files"
      ],
      "metadata": {
        "id": "b88PqfFTX91N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(enhanced_files[0])\n",
        "print(reference_files[0])\n",
        "print(len(enhanced_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIVRccYDZvDU",
        "outputId": "9f20f4d0-6107-44da-905c-78e2cdb5f5b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enhanced_signals_100tracks/scene_10001_L0057_remix.flac\n",
            "ref_signals_100/scene_10001_L0057_remix_ref.flac\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load listener data"
      ],
      "metadata": {
        "id": "1byRhXrc5nmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config.path.root = '/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE-6z8e6cdL",
        "outputId": "e94acd10-91ea-4093-fafd-82b028cf7bdd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'root': '/content/drive/MyDrive/Cadenza_Challenge/cad_icassp_2024', 'metadata_dir': '${path.root}/metadata', 'music_dir': '${path.root}/audio/at_mic_music', 'gains_file': '${path.metadata_dir}/gains.json', 'head_positions_file': '${path.metadata_dir}/head_positions.json', 'listeners_file': '${path.metadata_dir}/listeners.train.json', 'music_file': '${path.metadata_dir}/at_mic_music.train.json', 'scenes_file': '${path.metadata_dir}/scenes.train.json', 'scene_listeners_file': '${path.metadata_dir}/scene_listeners.train.json', 'exp_folder': './exp'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load listener audiograms and songs\n",
        "listener_dict = Listener.load_listener_dict(config.path.listeners_file)\n",
        "\n",
        "with Path(config.path.gains_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    gains = json.load(file)\n",
        "\n",
        "with Path(config.path.scenes_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    scenes = json.load(file)\n",
        "\n",
        "with Path(config.path.scene_listeners_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    scenes_listeners = json.load(file)\n",
        "\n",
        "with Path(config.path.music_file).open(\"r\", encoding=\"utf-8\") as file:\n",
        "    songs = json.load(file)"
      ],
      "metadata": {
        "id": "W00FlI6A5pnr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(songs)"
      ],
      "metadata": {
        "id": "G_ZMrGsTi04M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the enhancer (NAL-R) and compression setting (OFF)"
      ],
      "metadata": {
        "id": "OHqV6DQt7W2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enhancer = NALR(**config.nalr)\n",
        "compressor = Compressor(**config.compressor)"
      ],
      "metadata": {
        "id": "SvGqWrBN7cXa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list of songs, listeners (audiogram) and head position (hrtf) to generate, or evaluate the mix - based on provided data"
      ],
      "metadata": {
        "id": "UwQqYlq88GQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a batch to process\n",
        "scene_listener_pairs = make_scene_listener_list(\n",
        "    scenes_listeners, config.evaluate.small_test\n",
        ")\n",
        "\n",
        "scene_listener_pairs = scene_listener_pairs[\n",
        "    config.evaluate.batch :: config.evaluate.batch_size\n",
        "]"
      ],
      "metadata": {
        "id": "QSgNSyzC8U5e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scene_listener_pairs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW8ZQ0fE88nr",
        "outputId": "2d294b1e-fc6a-492d-eadb-cb3bf6421164"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('scene_10001', 'L0066')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load functions required for audio evaluation"
      ],
      "metadata": {
        "id": "3WKvkZkSLmgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add functions and variables needed for evaluation and scoring"
      ],
      "metadata": {
        "id": "QUy_emiYOI5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_headers = [\n",
        "    \"scene\",\n",
        "    \"song\",\n",
        "    \"listener\",\n",
        "    \"left_score\",\n",
        "    \"right_score\",\n",
        "    \"score\",\n",
        "]\n",
        "\n",
        "\n",
        "results_file = ResultsFile(\n",
        "            \"scores_100.csv\",\n",
        "            header_columns=scores_headers,\n",
        ")"
      ],
      "metadata": {
        "id": "sE2o-dKAOP8q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Audio - Currently set to process a fixed number of runs (listener - scene pairings, can be changed to run entire dataset)"
      ],
      "metadata": {
        "id": "GU9VumyD93Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previous_song = \"\"\n",
        "num_tracks = len(enhanced_files)\n",
        "\n",
        "for idx in range(1):\n",
        "    # Extract track, listener, scene info from file name\n",
        "    file_name = enhanced_files[idx]\n",
        "    sname = file_name.split(\"/\", 1)[1].split(\"_L\",1)[0]\n",
        "    lname = \"L\" +  file_name.split(\"/\", 1)[1].split(\"_L\",1)[1].split(\"_\")[0]\n",
        "\n",
        "    # Get the listener's audiogram\n",
        "    listener = listener_dict[lname]\n",
        "    scene = scenes[sname]\n",
        "    song_name = f\"{scene['music']}-{scene['head_loudspeaker_positions']}\"\n",
        "\n",
        "    print(sname)\n",
        "    print(lname)\n",
        "\n",
        "    # load audio files for HAAQI\n",
        "    reference_mixture = read_signal(\n",
        "            filename=reference_files[idx],\n",
        "            sample_rate=config.sample_rate,\n",
        "            allow_resample=True,\n",
        "        )\n",
        "\n",
        "    enhanced_mixture = read_signal(\n",
        "            filename=enhanced_files[idx],\n",
        "            sample_rate=config.sample_rate,\n",
        "            allow_resample=True,\n",
        "        )\n",
        "\n",
        "    # Evaluate - compare with the generated mixes\n",
        "    # Compute the scores\n",
        "    left_score = compute_haaqi(\n",
        "        processed_signal=resample(\n",
        "            enhanced_mixture[:, 0],\n",
        "            config.remix_sample_rate,\n",
        "            config.HAAQI_sample_rate,\n",
        "        ),\n",
        "        reference_signal=resample(\n",
        "            reference_mixture[:, 0], config.sample_rate, config.HAAQI_sample_rate\n",
        "        ),\n",
        "        processed_sample_rate=config.HAAQI_sample_rate,\n",
        "        reference_sample_rate=config.HAAQI_sample_rate,\n",
        "        audiogram=listener.audiogram_left,\n",
        "        equalisation=2,\n",
        "        level1=65 - 20 * np.log10(compute_rms(reference_mixture[:, 0])),\n",
        "    )\n",
        "\n",
        "    right_score = compute_haaqi(\n",
        "        processed_signal=resample(\n",
        "            enhanced_mixture[:, 1],\n",
        "            config.remix_sample_rate,\n",
        "            config.HAAQI_sample_rate,\n",
        "        ),\n",
        "        reference_signal=resample(\n",
        "            reference_mixture[:, 1], config.sample_rate, config.HAAQI_sample_rate\n",
        "        ),\n",
        "        processed_sample_rate=config.HAAQI_sample_rate,\n",
        "        reference_sample_rate=config.HAAQI_sample_rate,\n",
        "        audiogram=listener.audiogram_right,\n",
        "        equalisation=2,\n",
        "        level1=65 - 20 * np.log10(compute_rms(reference_mixture[:, 1])),\n",
        "    )\n",
        "\n",
        "        # Save scores\n",
        "    results_file.add_result(\n",
        "        {\n",
        "            \"scene\": sname,\n",
        "            \"song\": song_name,\n",
        "            \"listener\": listener.id,\n",
        "            \"left_score\": left_score,\n",
        "            \"right_score\": right_score,\n",
        "            \"score\": float(np.mean([left_score, right_score])),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(right_score, left_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqulZ1OilItP",
        "outputId": "a02bfdcd-7f07-4993-a029-b93f59b28f14"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scene_10001\n",
            "L0057\n",
            "0.13542157935034338 0.12934718417128538\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}